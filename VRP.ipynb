{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPfNa2nSqmDc"
      },
      "source": [
        "# Pip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7T7hy9SWLXDV"
      },
      "outputs": [],
      "source": [
        "# !pip freeze > requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGx1-cRi8dUf"
      },
      "source": [
        "# Experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "aPWVh5IuEykU"
      },
      "outputs": [],
      "source": [
        "result = {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtycZ3bi8gIR"
      },
      "source": [
        "## Node count = 10, wheel graphs, product count = 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKvfzpLIAF4y"
      },
      "source": [
        "### Generate data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Iqy0lFVUlqfO"
      },
      "outputs": [],
      "source": [
        "# parameters_dict = {\n",
        "#     'num_nodes': 3,\n",
        "#     'num_graphs': 100,\n",
        "#     'products_count': 1,\n",
        "#     'num_depots': 1,\n",
        "#     'k_vehicles': 2,\n",
        "#     'compartment_capacity': 50,\n",
        "#     'planning_horizon': 7,\n",
        "#     'noise_demand': 0.2,\n",
        "#     'batch_size':100,\n",
        "#     'seed':6,\n",
        "#     'epochs':15,\n",
        "#     'max_trips':2,\n",
        "#     'eval_epochs':3\n",
        "# }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "parameters_dict = {\n",
        "    'num_nodes': 3,\n",
        "    'num_graphs': 100,\n",
        "    'products_count': 2,\n",
        "    'num_depots': 1,\n",
        "    'k_vehicles': 2,\n",
        "    'compartment_capacity': 50,\n",
        "    'planning_horizon': 7,\n",
        "    'noise_demand': 0.2,\n",
        "    'batch_size':2,\n",
        "    'seed':6,\n",
        "    'epochs':100,\n",
        "    'max_trips':2,\n",
        "    'eval_epochs':1\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Zut6YbUX_2or"
      },
      "outputs": [],
      "source": [
        "from PSRP.problem_solvers.gnn.graph_generation_functions import create_wheel_noised\n",
        "\n",
        "\n",
        "dataset_dir='/content/drive/MyDrive/GraphDataset/wheel_10/'\n",
        "generation_function=create_wheel_noised\n",
        "node_dim = parameters_dict[\"products_count\"]*3 + 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1JPz93dDa8j",
        "outputId": "f1b3605b-c2f1-4b60-c26a-57fe1250b276"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\rkozl\\Desktop\\Sber\\PSRP\\problem_solvers\\gnn\\dataset_utils.py:95: RuntimeWarning: invalid value encountered in divide\n",
            "  min_capacities = min_capacities / max_capacities\n",
            "c:\\Users\\rkozl\\Desktop\\Sber\\PSRP\\problem_solvers\\gnn\\dataset_utils.py:96: RuntimeWarning: invalid value encountered in divide\n",
            "  init_capacities = init_capacities / max_capacities\n",
            "c:\\Users\\rkozl\\Desktop\\Sber\\PSRP\\problem_solvers\\gnn\\dataset_utils.py:97: RuntimeWarning: divide by zero encountered in divide\n",
            "  vehicle_compartments = vehicle_compartments / max_capacities\n",
            "c:\\Users\\rkozl\\Desktop\\Sber\\PSRP\\problem_solvers\\gnn\\dataset_utils.py:98: RuntimeWarning: invalid value encountered in divide\n",
            "  node_demand = np.array(plan_horizon_prods) / max_capacities\n",
            "c:\\Users\\rkozl\\Desktop\\Sber\\PSRP\\problem_solvers\\gnn\\dataset_utils.py:100: RuntimeWarning: divide by zero encountered in divide\n",
            "  load = load / max_capacities\n",
            "c:\\Users\\rkozl\\Desktop\\Sber\\PSRP\\problem_solvers\\gnn\\dataset_utils.py:101: RuntimeWarning: invalid value encountered in divide\n",
            "  max_capacities = max_capacities / max_capacities\n",
            "100%|██████████| 100/100 [00:00<00:00, 223.31it/s]\n"
          ]
        }
      ],
      "source": [
        "from PSRP.problem_solvers.gnn.dataset_utils import CustomImageDataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "dataset = CustomImageDataset(dataset_dir=dataset_dir,\n",
        "        generation_function=generation_function,\n",
        "        parameters_dict=parameters_dict)\n",
        "\n",
        "train_dataloader = DataLoader(dataset, batch_size=parameters_dict['batch_size'], shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "2RyxJucaFF0b"
      },
      "outputs": [],
      "source": [
        "from PSRP.problem_solvers.gnn.RL.agent import IRPAgent\n",
        "\n",
        "agent_irp = IRPAgent(node_dim=node_dim, seed=parameters_dict['seed'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7zLZr4D_Thj",
        "outputId": "6397a96d-78cc-4c83-86f5-24e80738b83c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/100 [00:00<?, ?it/s]c:\\Users\\rkozl\\Desktop\\Sber\\PSRP\\problem_solvers\\gnn\\RL\\envipoment.py:162: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  avarage_stock = (np.einsum('ijk->',self.init_capacities[self.day_end]) / np.einsum('ijk->', self.max_capacities[self.day_end]))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "replacing baceline\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/100 [00:36<?, ?it/s]\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from PSRP.problem_solvers.gnn.RL.train import train\n",
        "\n",
        "loss_history, dist_history, dry_runs_history, kpi = train(agent_irp,\n",
        "            train_dataloader,\n",
        "            parameters_dict,\n",
        "            check_point_dir=f\"./check_points/my_irp_{parameters_dict['num_nodes']}_{parameters_dict['seed']}/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8CjUaDf1vlj"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "linspace = range(len(dist_history))\n",
        "\n",
        "figure, axis = plt.subplots(1, 3, figsize=(15,6))\n",
        "\n",
        "axis[0].plot(linspace, dist_history)\n",
        "axis[0].set_title(\"Расстояние\")\n",
        "axis[0].grid()\n",
        "axis[0].set_xlabel(\"Episodes\")\n",
        "axis[0].set_ylabel(\"Value\")\n",
        "\n",
        "\n",
        "axis[1].plot(linspace, dry_runs_history)\n",
        "axis[1].set_title(\"Пересыхания\")\n",
        "axis[1].grid()\n",
        "axis[1].set_xlabel(\"Episodes\")\n",
        "axis[1].set_ylabel(\"Value\")\n",
        "\n",
        "axis[2].plot(linspace, loss_history)\n",
        "axis[2].set_title(\"(loss_m - loss_b) * -1 * log_prob\")\n",
        "axis[2].grid()\n",
        "axis[2].set_xlabel(\"Episodes\")\n",
        "axis[2].set_ylabel(\"Value\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDdcpinsAwTb"
      },
      "source": [
        "### Pred on CPSAT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tE5RnWoxXjeW"
      },
      "outputs": [],
      "source": [
        "# num_nodes = 10\n",
        "# synth_data = create_wheel_noised(num_nodes)\n",
        "# data_nn, data_cpsat = get_graph_dict(synth_data,\n",
        "#                                      num_nodes,\n",
        "#                                      products_count,\n",
        "#                                      compartment_capacity,\n",
        "#                                      7,\n",
        "#                                      k_vehicles=k_vehicles,\n",
        "#                                      noise_demand=0.0,\n",
        "#                                      draw=True)\n",
        "\n",
        "data_nn = dataset[0]\n",
        "data_cpsat = dataset.model_for_cpsat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sE6BFej-_shS"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "from pprint import pprint\n",
        "import time\n",
        "\n",
        "from PSRP.problem_solvers.mppsrp.cpsat.TaskBuilder_MPPSRP_FullMILP_CPSAT import TaskBuilder_MPPSRP_FullMILP_CPSAT\n",
        "from PSRP.problem_solvers.mppsrp.cpsat.TaskSolver_MPPSRP_CPSAT import TaskSolver_MPPSRP_CPSAT\n",
        "# from PSRP.problem_solvers.mppsrp.data_generators.DataBuilder_MPPSRP_FullMILP_CPSAT import DataBuilder_MPPSRP_FullMILP_CPSAT\n",
        "\n",
        "from PSRP.paths_config import interim_dir\n",
        "\n",
        "task_builder = TaskBuilder_MPPSRP_FullMILP_CPSAT( max_trips_per_day=parameters_dict['max_trips'], verbose=True )\n",
        "task = task_builder.build_task( data_cpsat )\n",
        "\n",
        "print(\"Solving start time: {}\".format( datetime.now() ))\n",
        "task_solver = TaskSolver_MPPSRP_CPSAT( cache_dir=interim_dir,\n",
        "                                       cache_all_feasible_solutions=False,\n",
        "                                       solution_prefix='dataset',\n",
        "                                       time_limit_milliseconds=60_000)\n",
        "start_time = time.time()\n",
        "solution = task_solver.solve( task )\n",
        "delta_time = time.time() - start_time\n",
        "print('kpi')\n",
        "kpi_dict = solution.get_kpis()\n",
        "pprint( kpi_dict )\n",
        "\n",
        "print()\n",
        "routes_schedule = solution.get_routes_schedule()\n",
        "pprint( routes_schedule )\n",
        "\n",
        "print(\"done\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugxVJGUsFvI8"
      },
      "source": [
        "### Pred on model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ugxVJGUsFvI8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "item = dataset[0]\n",
        "new_item = []\n",
        "for i in range(len(item)):\n",
        "  new_item.append(np.expand_dims(item[i], axis=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "from copy import deepcopy\n",
        "\n",
        "from PSRP.problem_solvers.gnn.RL.envipoment import IRPEnv_Custom\n",
        "\n",
        "temp_data = deepcopy(new_item)\n",
        "\n",
        "env_irp = IRPEnv_Custom(temp_data,\n",
        "                        parameters_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IsBhctg_lDy",
        "outputId": "461b52cc-ddb7-40fd-d3d8-5f2d7c84478d"
      },
      "outputs": [],
      "source": [
        "start_time = time.time()\n",
        "loss_a, kpi = agent_irp.evaluate(env_irp)\n",
        "delta_time_model = time.time() - start_time\n",
        "\n",
        "print(loss_a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for e in zip(kpi['load_percents'], [e.item() for e in kpi['actions_list']]):\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P4_Cj-VxCrOI"
      },
      "outputs": [],
      "source": [
        "actions = [e.item() for e in kpi['actions_list']]\n",
        "m = data_cpsat['distance_matrix']\n",
        "t = data_cpsat['travel_time_matrix']\n",
        "\n",
        "time_delta = 18*60*60 - 9*60*60\n",
        "\n",
        "sum_dist = 0\n",
        "sum_time = 0\n",
        "global_sum_time = 0\n",
        "exceeded_time = 0\n",
        "actions.insert(0,0)\n",
        "print(actions)\n",
        "for i in range(len(actions)-1):\n",
        "  start = actions[i]\n",
        "  end = actions[i+1]\n",
        "  dist = m[start][end]\n",
        "  edge_time = t[start][end]\n",
        "  sum_time += edge_time\n",
        "  global_sum_time += edge_time\n",
        "  sum_dist += dist\n",
        "\n",
        "  if end == 0 and sum_time > time_delta:\n",
        "    # print(start, end)\n",
        "    exceeded_time += 1\n",
        "    sum_time = 0\n",
        "  print(f'{start} -> {end} : dist = {dist} time = {edge_time}')\n",
        "\n",
        "print()\n",
        "print(f'sum_dist={sum_dist}, sum_time={global_sum_time}, exceeded_time = {exceeded_time}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "kpi['dry_runs']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLdAp4WHr_yj"
      },
      "outputs": [],
      "source": [
        "\n",
        "from PSRP.problem_solvers.gnn.utils import divide_to_paths_nn\n",
        "\n",
        "\n",
        "nn_paths = divide_to_paths_nn(actions)\n",
        "lengths = []\n",
        "for e in nn_paths:\n",
        "  if not np.all(np.array(e) == 0):\n",
        "    lengths.append(len(e))\n",
        "np.array(lengths).mean()\n",
        "\n",
        "kpi['mean_stops'] = np.array(lengths).mean()\n",
        "\n",
        "actions_daily = kpi['actions_daily']\n",
        "for key in actions_daily:\n",
        "  actions_daily[key] =[e.item() for e in actions_daily[key]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2b2AF5FBag0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "result['wheel_10_3'] = {\n",
        "        'sum_dist_cpsat':kpi_dict['total_travel_distance'],\n",
        "        'sum_dist_model':sum_dist,\n",
        "        'error': (kpi_dict['total_travel_distance'] - sum_dist) / kpi_dict['total_travel_distance'],\n",
        "        'time_cpsat':delta_time,\n",
        "        'time_model':delta_time_model,\n",
        "        'dry_runs_model':sum(list(kpi['dry_runs'].values())),\n",
        "        'dry_runs_cpsat':kpi_dict['dry_runs'],\n",
        "    }\n",
        "pd.DataFrame.from_dict(result, orient='index',).round(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from PSRP.problem_solvers.gnn.utils import draw_paths\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import networkx as nx\n",
        "\n",
        "import matplotlib.colors as mcolors\n",
        "\n",
        "def draw_paths(data_nn, routes):\n",
        "  G = nx.Graph()\n",
        "  edges = []\n",
        "  for r in routes:\n",
        "      route_edges = [(r[n],r[n+1]) for n in range(len(r)-1)]\n",
        "      G.add_nodes_from(r)\n",
        "      G.add_edges_from(route_edges)\n",
        "      edges.append(route_edges)\n",
        "\n",
        "  print(\"Graph has %d nodes with %d edges\" %(G.number_of_nodes(),\n",
        "  G.number_of_edges()))\n",
        "\n",
        "  pos = data_nn[0]\n",
        "  nx.draw_networkx_nodes(G,pos=pos)\n",
        "  nx.draw_networkx_labels(G,pos=pos)\n",
        "  colors = list(mcolors.TABLEAU_COLORS.keys())\n",
        "  for ctr, edgelist in enumerate(edges):\n",
        "      nx.draw_networkx_edges(G,pos=pos,edgelist=edgelist,edge_color = colors[ctr % len(colors)], width=5)\n",
        "  plt.savefig('this.png')\n",
        "  plt.show()\n",
        "  \n",
        "  \n",
        "def divide_to_paths_nn(actions):\n",
        "\n",
        "  particular_value = 0\n",
        "  result = []\n",
        "  temp_list = []\n",
        "  for i in actions:\n",
        "      if i == particular_value:\n",
        "          temp_list.append(i)\n",
        "          result.append(temp_list)\n",
        "          temp_list.insert(0,0)\n",
        "          temp_list = []\n",
        "      else:\n",
        "          temp_list.append(i)\n",
        "  result.append(temp_list)\n",
        "  result.pop(0)\n",
        "  result.pop(-1)\n",
        "  return result\n",
        "\n",
        "def divide_to_path_cpsat(routes_schedule):\n",
        "  result_paths = []\n",
        "  for car in routes_schedule[0]:\n",
        "    for e in car:\n",
        "      result_paths.append(e[0])\n",
        "  return result_paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUXaj3t9A1UU"
      },
      "outputs": [],
      "source": [
        "\n",
        "nn_paths = divide_to_paths_nn(actions)\n",
        "print(nn_paths)\n",
        "draw_paths(data_nn, nn_paths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hreVF6YgICLh"
      },
      "outputs": [],
      "source": [
        "\n",
        "nn_paths = divide_to_paths_nn(actions_daily[1.0])\n",
        "print(len(nn_paths))\n",
        "draw_paths(data_nn, nn_paths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtAwHOwlIEiW"
      },
      "outputs": [],
      "source": [
        "nn_paths = divide_to_paths_nn(actions_daily[3.0])\n",
        "print(len(nn_paths))\n",
        "draw_paths(data_nn, nn_paths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80ZpUbWxIHDJ"
      },
      "outputs": [],
      "source": [
        "nn_paths = divide_to_paths_nn(actions_daily[4.0])\n",
        "print(len(nn_paths))\n",
        "draw_paths(data_nn, nn_paths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZeB0KKv4GFnW"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "nn_paths = divide_to_paths_nn(actions_daily[5.0])\n",
        "print(len(nn_paths))\n",
        "draw_paths(data_nn, nn_paths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fl3ITJalGIEW"
      },
      "outputs": [],
      "source": [
        "nn_paths = divide_to_paths_nn(actions_daily[6.0])\n",
        "print(len(nn_paths))\n",
        "draw_paths(data_nn, nn_paths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCD88jg5KinG"
      },
      "outputs": [],
      "source": [
        "actions_daily"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4YRnk6ryGKSv"
      },
      "outputs": [],
      "source": [
        "nn_paths = divide_to_paths_nn(actions_daily[7.0])\n",
        "print(len(nn_paths))\n",
        "draw_paths(data_nn, nn_paths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_PS4EzqqCGO8"
      },
      "outputs": [],
      "source": [
        "from PSRP.problem_solvers.gnn.utils import divide_to_path_cpsat\n",
        "\n",
        "\n",
        "cpsat_path = divide_to_path_cpsat(routes_schedule)\n",
        "draw_paths(data_nn, cpsat_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJ0T9VOAdR2b"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "CBqdCBZ_qkgN",
        "JTq_Z8cCo29U",
        "n5jcEAKlo4AW",
        "JOR_NBlxpEWk",
        "USK6Yy_mpJL4",
        "if5i_uVLp7-N",
        "Ov8iC4KvpVlm",
        "6iNHU4XRpakf",
        "jFFXzuJepm5G",
        "B4skpAYipv5h",
        "EVutIRFOqRQU",
        "Iz5U8Qqn6DhQ",
        "c5QSpYJ3_zfI",
        "i2CU2v01_1g9"
      ],
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30733,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
